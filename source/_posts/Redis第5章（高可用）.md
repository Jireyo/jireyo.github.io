---
title: Redis第5章（高可用）
categories:
 - [八股,Redis,基础]
date: 2023-01-04 03:00:37
tag:
 - Redis
 - 八股
---
# 主从复制
>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；

**主从复制的作用**主要包括：
性能上：
- **负载均衡**：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
- **读写分离**：
	- 读操作：主库、从库都可以接收；
	- 写操作：首先到主库执行，然后，主库将写操作同步给从库。
稳定性上：
- **数据冗余**：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
- **故障恢复**：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
- **高可用基石**：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。


## 原理
### 连接
1.从节点 发送指令replicaof ip port，主节点接受并响应
2.从节点 连接master的socket
3.从节点 发送指令auth password
4.主节点 验证授权
5.从节点 发送自身信息，主节点保存slave

### 复制
- 全量复制
- 增量复制

#### 全量复制
![](Pasted-image-20230104040638.jpg)
**第一阶段**：主从库间建立连接、协商同步的过程。
- 从节点发送psync命令，其应该包含主库的runId和offset，但这是初次复制，所以发送的runId=?,offset=-1。
- 主节点回复FULLRESYNC，并携带runId和offset，告诉从节点自身信息。
**第二阶段**：主库将所有数据同步给从库。
- 主库执行bgsave，将其发送给RDB。
- 从库接受到RDB时，先清空数据库，再加载RDB。
- 主库在这一阶段会把新的写命令记录在repl buffer中。
**第三阶段**：主库发送期间同步期间产生的新的写命令。
{% note primary %}
注意这里的repl buffer，前面讲AOF持久化时，也有一个aof_buffer，用于记录**重写**时的新写入命令。
{% endnote %}

#### 增量复制
>每次都全量复制的开销过大。

![](Pasted-image-20230104041537.jpg)

`repl_backlog_buffer`：环形缓冲区，用于记录写命令（会覆盖）。repl_baklog文件记录了命令偏移，**主节点的offset**和**从节点的offset**（但还是会以从节点ask发来的offset为准）。

`replication buffer`：每个client连上Redis后，**Redis都会分配一个client buffer**，所有数据交互都是通过这个buffer进行的。Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。repl buffer的默认大小为1M。

#### 全量复制还是增量复制？
从库会记录自己的`slave_repl_offset`，恢复连接时，从库会通过`psync`发送自己的offset，主库根据这个offset判断进行增量还是全量复制。（如果`repl_backlog_buffer`的`slave_repl_offset`已经被覆盖，进全量复制）。

![](202207221741726.png)

### 心跳
#### 功能
![](202207221741728.png)
{% note primary %}
主从节点都会发心跳，目的都有判断对方是否在线，此外从节点还会汇报自己的复制进度。
{% endnote %}
#### 机制
![](202207221741729.png)
#### 流程
![](202207221741730.png)

## 深入理解
### 主服务器持久化与安全性
- 主从复制时，主服务器强烈建议开启持久化。
- 若主节点没有开启持久化，又开启了自动重启，重启后主节点数据库为空，而从节点对其进行全量复制，会导致从节点数据也被删除。
- 所以，若主节点没有开启持久化，应该禁止自动重启。

### 为什么主从全量复制使用RDB而不使用AOF
- RDB文件很小，适合传输
- RDB加载很快，适合恢复
- AOF使用不当，会严重影响Redis性能

### 无磁盘复制模式
主服务器磁盘速度较低时，RDB会带来一些负担，**无磁盘复制模式**是指：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。适用于disk较慢，并且网络较快的时候。
使用`repl-diskless-sync`配置参数来启动无磁盘复制。

### 从库的从库
对于主库来说，需要完成两个耗时的操作：**生成 RDB 文件和传输 RDB 文件**。
通过“主 - 从 - 从”模式可以**将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上**。
![](Pasted-image-20230104045116.jpg)
后续的写同步也可以级联传播。

### 读写分离
#### 延迟与不一致问题
**优化**：优化网络环境、舍弃大延迟从节点，使用集群扩展读负载能力。
#### 数据过期
单机redis的删除策略
 - **惰性删除**：客户端查询数据时才判断是否过期，过期则删除
 - **定期删除**：服务器定时任务删除过期数据
主从复制时，从节点不主动删除，而是由主节点控制从节点删除（保证数据一致性），但由于主节点不会立即删除过期数据，客户端在从节点上容易读到过期数据。
**解决**：Redis3.2中，从节点也会判断数据过期。

#### 故障切换
主/从节点发生故障时，要及时切换客户端的Redis连接。
- 手动：响应慢，容易出错
- 监控程序：实现复杂
{% note primary %}
使用哨兵即可解决这个问题。
{% endnote %}

#### 总结
在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。

# 哨兵机制
>哨兵Redis Sentinel的核心功能是协助完成自动故障转移。

## 功能
- 监控：监听主从节点运作
- 自动故障转移：更改主节点
- 配置提供：向客户端提供节点信息
- 通知：通知客户端故障转移的结果

## 原理
### 集群组建
![](Pasted-image-20230104223227.jpg)
- 主节点上有一个`_sentinel_:hello`频道，哨兵们通过该频道实现互相发现。
- 互相发现后哨兵之间建立连接。
### 监控Redis库
![](Pasted-image-20230104223410.jpg)
- 哨兵向主节点发送`INFO`命令，根据接受到的Slave列表与各从库建立连接

### 主库下线判断
下线概念：
- **主观下线**：任何一个哨兵都是可以监控探测，并作出Redis节点下线的判断；
- **客观下线**：有哨兵集群共同决定Redis节点是否下线；
![](Pasted-image-20230104223530.jpg)
- 哨兵判断主库下线后，向其他哨兵发送`is-master-down-by-addr`命令，其他哨兵作出Y或N响应。
- 如果赞成票大于配置项`quorum`，判定主库客观下线。

### 哨兵集群的选举
客观下线后，需要选举一个主哨兵执行最终调整命令
- 选举算法：
	- Raft选举算法： 选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举
- 成为Leader的前提：
	- 第一，拿到半数以上的赞成票；
	- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 `quorum` 值。

{% note primary %}
这里注意，判断客观下线需要得到大于`quorum`的赞成票，选举leader需要半数以上**且**大于`quorum`值的赞成票。
即，若有哨兵掉线导致无法超过半数，也无法实现Leader选举
{% endnote %}

### 新主库选择
- 过滤掉不健康的（下线或断线），没有回复过哨兵ping响应的从节点
- 选择`salve-priority`从节点优先级最高（redis.conf）的
- 选择复制偏移量最大，只复制最完整的从节点

{% note primary %}
先选活的，再选关系户，最后选有实力的，都没法就选runID小的。
{% endnote %}
### 故障转移
![](Pasted-image-20230104224208.png)
- 让新主库脱离原主库（replicaof no one）
- 让其他从库成为新主库的从节点
- 通知应用程序新redis主节点
- 原主库上线后变成新主节点的从节点

# 分片技术
>主从复制解决了主节点崩溃的备份问题，并通过读写分离提高了性能。
>哨兵机制解决了主节点崩溃时的崩溃转移问题。
>但这都没有扩展Redis的写能力和存储能力，因此Redis引入了集群的功能。

## 主要模块
### 哈希槽(Hash Slot)
Redis-cluster没有使用一致性hash，而是引入了**哈希槽**的概念。Redis-cluster中有**16384(即2的14次方)个哈希槽**，每个key通过CRC16校验后对16383取模来决定放置哪个槽。Cluster中的每个节点负责一部分hash槽（hash slot）。

### Keys hash tags
Hash tags提供了一种途径，**用来将多个(相关的)key分配到相同的hash slot中**。这时Redis Cluster中实现multi-key操作的基础。
hash tag规则如下，如果满足如下规则，`{`和`}`之间的字符将用来计算HASH_SLOT，以保证这样的key保存在同一个slot中。

例如：hash("{user1}.name") == hash("{user1}.age")

### Cluster nodes属性
每个**节点在cluster中有一个唯一的名字**。
这个名字由160bit随机十六进制数字表示，并在节点启动时第一次获得(通常通过/dev/urandom)。节点在配置文件中保留它的ID，并永远地使用这个ID，直到被管理员使用CLUSTER RESET HARD命令hard reset这个节点。
这样节点可以实现IP的变化而不影响其在集群中的定位。

每个节点维护集群内其他节点的以下信息：
- `node id`，`节点的IP和port`，`节点标签`，`master node id`（如果这是一个slave节点）
- `最后被挂起的ping的发送时间`(如果没有挂起的ping则为0)，`最后一次收到pong的时间`
- `当前的节点configuration epoch`（配置版本号） ，`链接状态`，以及该节点服务的`hash slots`。

{% note primary %}
即维护基本身份（node id,ip port,从属）,存活信息（ping pong），服务信息（版本号、连接、slots）
{% endnote %}

### Cluster总线
每个Redis Cluster节点有一个额外的TCP端口用来接受其他节点的连接。

这个端口与用来接收client命令的普通TCP端口有一个固定的offset。如该端口等于普通命令端口加上10000.例如，一个Redis街道口在端口6379坚挺客户端连接，那么它的集群总线端口16379也会被打开。

>节点到节点的通讯只使用集群总线，同时使用集群总线协议：有不同的类型和大小的帧组成的二进制协议。

### 节点握手
节点总是接受集群总线端口的链接，并且总是会回复ping请求，即使ping来自一个不可信节点。然而，如果发送节点被认为不是当前集群的一部分，所有其他包将被抛弃。

节点认定其他节点是当前集群的一部分有两种方式（阶段）：
- 节点接受到一条meet消息，其会将meet消息的发送节点视为集群内节点。
- 节点接受到其信任的节点的gossip信息，其会将gossip信息中提到的新节点标记为集群内节点。

### 集群拓扑
Redis Cluster是一张全网拓扑，节点与其他每个节点之间都保持着TCP连接。
节点之间使用gossip协议更新避免过多的消息交换。

{% note danger %}
上面主要是cluster的主要模块，涉及到以下几个方面：
- 分片：使用了**哈希槽**的方法对键进行分片，同时使用**keys hash tags**技术实现了定向的分片。
- 通讯：节点会开启**cluster总线**监听、返回消息，其会记录各个**cluster nodes**的基本信息。
- **握手**：节点监听到meet消息或信任节点的gossip消息会将目标节点加入到集群内。
{% endnote %}

## 具体过程
### 请求重定向
- 检查当前key是否存在当前NODE？
    - 通过crc16（key）/16384计算出slot
    - 查询负责该slot负责的节点，得到节点指针
    - 该指针与自身节点比较
- 若slot不是由自身负责，则返回MOVED重定向
- 若slot由自身负责，且key在slot中，则返回该key对应结果
- 若key不存在此slot中，检查该slot是否正在迁出（MIGRATING）？
- 若key正在迁出，返回ASK错误重定向客户端到迁移的目的服务器上
- 若Slot未迁出，检查Slot是否导入中？
- 若Slot导入中且有ASKING标记，则直接操作
- 否则返回MOVED重定向
#### MOVED重定向
![](Pasted-image-20230104233215.png)

#### ASK重定向
![](Pasted-image-20230104233422.png)

#### SMART客户端
上述两种重定向的机制使得客户端的实现更加复杂，提供了smart客户端（JedisCluster）来**减低复杂性，追求更好的性能**。
![](Pasted-image-20230104233615.png)

客户端通过cluster slots命令获取集群信息，依据其自主计算目标key所在的节点，直接对目标节点进行访问。

>失败时，进行随机访问节点、更新自身映射表并重新访问，若失败过多则放弃。

{% note warning %}
简而言之，客户端请求后，节点判断是否由自己处理，不由自己处理则MOVED，由自己处理但发现slot已经迁移则ASK。
SMART客户端则自身计算slots的工作，映射失效时则随机访问节点刷新映射。
{% endnote %}

### 状态检测
Cluster中的每个节点都维护一份在自己看来当前整个集群的状态，主要包括：
- 当前集群状态
- 集群中各节点所负责的slots信息，及其migrate状态
- 集群中各节点的master-slave状态
- 集群中各节点的存活状态及不可达投票

#### Gossip协议
gossip 协议（gossip protocol）又称 epidemic 协议（epidemic protocol）是一种P2P2协议，Gossip协议的最大的好处是，**即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。这就允许Consul管理的集群规模能横向扩展到数千个节点**。

Redis 集群是去中心化的，彼此之间状态同步靠 gossip 协议通信，集群的消息有以下几种类型：
- `Meet` 通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。
- `Ping` 节点每秒会向集群中其他节点发送 ping 消息，消息中带有自己已知的两个节点的地址、槽、状态信息、最后一次通信时间等。
- `Pong` 节点收到 ping 消息后会回复 pong 消息，消息中同样带有自己已知的两个节点信息。
- `Fail` 节点 ping 不通某节点后，会向集群所有节点广播该节点挂掉的消息。其他节点收到消息后标记已下线。

{% note primary %}
meet用于新增节点，ping/pong维护，fail用于下线节点
{% endnote %}

#### 故障检测
在某节点看来，其他节点的状态有**在线状态**、**疑似下线状态PFAIL**、**已下线状态FAIL**。

- 节点A发现某节点B下线时，将其标记为PFAIL，并通知附近节点C。
- 节点C接受到消息后，确认真假，将该状态记录并继续传播PFAIL消息。
- 最后节点判断其是否客观下线（**自己认为** 且 **发现过半节点认为其疑似下线PFIAL**），若客观下线，其会发送FAIL消息让所有节点接受节点A客观下线。

### 通讯维护
#### 什么时候进行心跳？
Redis节点会记录其向每一个节点上一次发出ping和收到pong的时间，心跳发送时机与这两个值有关。通过下面的方式既能保证及时更新集群状态，又不至于使心跳数过多：

- 每次Cron向所有未建立链接的节点发送ping或meet
- 每1秒从所有已知节点中随机选取5个，向其中上次收到pong最久远的一个发送ping
- 每次Cron向收到pong超过timeout/2的节点发送ping
- 收到ping或meet，立即回复pong

#### 发送哪些心跳数据？

- Header，发送者自己的信息
    - 所负责slots的信息
    - 主从信息
    - ip port信息
    - 状态信息
-   Gossip，发送者所了解的部分其他节点的信息
    - ping_sent, pong_received
    - ip, port信息
    - 状态信息，比如发送者认为该节点已经不可达，会在状态信息中标记其为PFAIL或FAIL

#### 如何处理心跳？
##### 新节点加入
- 发送meet包加入集群
- 从pong包中的gossip得到未知的其他节点
- 循环上述过程，直到最终加入集群
![](Pasted-image-20230104235107.png)

##### Slots消息
- 判断发送者声明的slots信息，跟本地记录的是否有不同
- 如果不同，且发送者epoch较大，更新本地记录
- 如果不同，且发送者epoch小，发送Update信息通知发送者

##### Master slave信息
发现发送者的master、slave信息变化，更新本地状态

##### 节点Fail探测(故障发现)
超时没有收到某节点pong包，标记其PFAIL，并在pong时传播这个标记。

>注：Gossip的存在使得集群状态的改变可以更快的达到整个集群。每个心跳包中会包含多个Gossip包，那么多少个才是合适的呢，redis的选择是N/10，其中N是节点数，这样可以保证在PFAIL投票的过期时间内，节点可以收到80%机器关于失败节点的gossip，从而使其顺利进入FAIL状态。

### 故障恢复（Failover）
#### 手动
通过某个slave执行cluster failover命令，手动让某个master宕机，并将本slave作为master节点。
此时命令还包括一些流程处理，如校验offset，查看master状态和询问其他master意见等。

#### 自动
当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave。Failover的过程需要经过类Raft协议的过程在整个集群内达到一致，其过程如下：
- slave发现自己的master变为FAIL
- 将自己记录的集群currentEpoch加1，并广播Failover Request信息
- 其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack
- 尝试failover的slave收集FAILOVER_AUTH_ACK
- 超过半数后变成新Master
- 广播Pong通知其他集群节点
![](Pasted-image-20230105001028.png)

### 扩容&缩容
### 扩容
1. 首先将新节点加入到集群中，可以通过在集群中任何一个客户端执行cluster meet 新节点ip:端口，或者通过redis-trib add node添加，新添加的节点默认在集群中都是主节点。
2. 迁移数据 迁移数据的大致流程是，首先需要确定哪些槽需要被迁移到目标节点，然后获取槽中key，将槽中的key全部迁移到目标节点，然后向集群所有主节点广播槽（数据）全部迁移到了目标节点。

### 缩容

缩容的大致过程与扩容一致，需要判断下线的节点是否是主节点，以及主节点上是否有槽，若主节点上有槽，需要将槽迁移到集群中其他主节点，槽迁移完成之后，需要向其他节点广播该节点准备下线（cluster forget nodeId）。最后需要将该下线主节点的从节点指向其他主节点，当然最好是先将从节点下线。

## 更深入理解
### 为什么Redis Cluster的Hash Slot是16384？
我们知道一致性hash算法是2的16次方（65535），为什么hash slot是2的14次方（16384）呢？

在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，使用bitmap压缩，16384bit = 16kb = 2kB，也就是说使用2kB的空间创建了16k的槽数。如果使用CRC16分配65535个槽位，需要使用8kB才行，作者认为没有必要。

### 为什么Redis Cluster中不建议使用发布订阅呢？
在集群模式下，所有的publish命令都会向所有节点（包括从节点）进行广播，造成每条publish数据都会在集群内所有节点传播一次，加重了带宽负担，对于在有大量节点的集群中频繁使用pub，会**严重消耗带宽**，不建议使用。（虽然官网上讲有时候可以使用Bloom过滤器或其他算法进行优化的。


todo:对比哨兵和集群的交流，维护机制
通讯维护部分详细化。